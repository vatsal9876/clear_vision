{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vatsal9876/image_restoration/blob/main/VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, backend as K"
      ],
      "metadata": {
        "id": "jT6z0N9KAh6q"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 128\n",
        "img_shape = (64, 64, 3) # must change input shape"
      ],
      "metadata": {
        "id": "eLrjKTbiAsL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def latent_sampling(z_args):\n",
        "    z_mean, z_log_var = z_args\n",
        "    epsilon = tf.random.normal(shape=(tf.shape(z_mean)[0], latent_dim))\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "id": "p5NP-NzvBGFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vae_structure():\n",
        "  # Encoder\n",
        "    inputs = layers.Input(shape=img_shape)\n",
        "    x = layers.Conv2D(32, 3, activation='relu', strides=2, padding='same')(inputs)\n",
        "    x = layers.Conv2D(64, 3, activation='relu', strides=2, padding='same')(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "\n",
        "    z_mean = layers.Dense(latent_dim)(x)\n",
        "    z_log_var = layers.Dense(latent_dim)(x)\n",
        "    z_args = [z_mean, z_log_var]\n",
        "\n",
        "    z = layers.Lambda(latent_sampling)(z_args)\n",
        "\n",
        "    # Decoder\n",
        "    decoder_input = layers.Input(shape=(latent_dim,))\n",
        "    x = layers.Dense(16 * 16 * 64, activation='relu')(decoder_input)\n",
        "    x = layers.Reshape((16, 16, 64))(x)\n",
        "    x = layers.Conv2DTranspose(64, 3, strides=2, activation='relu', padding='same')(x)\n",
        "    x = layers.Conv2DTranspose(32, 3, strides=2, activation='relu', padding='same')(x)\n",
        "    decoded_output = layers.Conv2D(3, 3, activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    decoder = Model(decoder_input, decoded_output, name='decoder')\n",
        "\n",
        "    outputs = decoder(z)\n",
        "    vae = VAEModel(inputs, outputs, z_mean, z_log_var, decoder)\n",
        "    return vae"
      ],
      "metadata": {
        "id": "6P_fBgrkBw3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAEModel(Model):\n",
        "    def __init__(self, encoder_inputs, decoded_outputs, z_mean, z_log_var, decoder, **kwargs):\n",
        "        super(VAEModel, self).__init__(**kwargs)\n",
        "        self.encoder_inputs = encoder_inputs\n",
        "        self.decoded_outputs = decoded_outputs\n",
        "        self.z_mean = z_mean\n",
        "        self.z_log_var = z_log_var\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def compile(self, optimizer):\n",
        "        super(VAEModel, self).compile()\n",
        "        self.optimizer = optimizer\n",
        "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
        "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(name=\"reconstruction_loss\")\n",
        "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_tracker, self.reconstruction_loss_tracker, self.kl_loss_tracker]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        noisy_images, clean_images = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var = self.encode(noisy_images)\n",
        "            z = latent_sampling([z_mean, z_log_var])\n",
        "            reconstruction = self.decoder(z)\n",
        "\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.keras.losses.binary_crossentropy(clean_images, reconstruction)\n",
        "            ) * img_shape[0] * img_shape[1] * img_shape[2]\n",
        "\n",
        "            kl_loss = -0.5 * tf.reduce_mean(\n",
        "                1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
        "            )\n",
        "\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "\n",
        "        self.loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "\n",
        "        return {\n",
        "            \"loss\": self.loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n",
        "\n",
        "    def encode(self, x):\n",
        "        encoder = tf.keras.Model(self.encoder_inputs, [self.z_mean, self.z_log_var])\n",
        "        return encoder(x)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = self.encode(inputs)\n",
        "        z = latent_sampling([z_mean, z_log_var])\n",
        "        return self.decoder(z)"
      ],
      "metadata": {
        "id": "DlgxsVk3Cbil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae = vae_structure()\n",
        "vae.compile(optimizer=tf.keras.optimizers.Adam())"
      ],
      "metadata": {
        "id": "SbU5cQqvC-EH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}